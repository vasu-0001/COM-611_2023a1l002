{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ccd59b-7302-408b-b7f0-5e9eedd8afcd",
   "metadata": {},
   "source": [
    "### Implement the detection of eye or face or smile from given Image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d22350-08e5-4d25-a4a9-807a372db373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538a340-788f-49f6-8de6-ded25de1bbd3",
   "metadata": {},
   "source": [
    "##### face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml'):\n",
    "\n",
    "##### This line creates the instance of the CascadeClassifer from OpenCV, which is used for detecting images.\n",
    "\n",
    "##### The cv2.data.haarcascades is a pre-defined path in OpenCV that refers to the directory conatining the HaarCascades XML files.\n",
    "\n",
    "##### 'haarcascades_frontalface_default.xml' is the XML file that contains the trained model for face detection using the Haar cascades algorithm.\n",
    "##### It specifically used for frontal faces .\n",
    "\n",
    "##### The trained model is loaded into the face_cascade object, which can then be used to detect faces in images or video frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "299130ed-7d8e-4f76-8f5c-039696f9be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load models\n",
    "face_cascade= cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade= cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "smile_cascade= cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb7b9a5-8785-4f27-a923-72dbe4514520",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3ba82-76c9-486a-a996-5f4bdcef706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('exp 9_image.jpg')\n",
    "cv2.imshow(\"Image:\", img)  # Use cv2.imshow instead\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d812f26a-51ef-45eb-a19e-26655650f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Grayscale Image\",gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40838b3d-383b-4dbc-9f8b-a4b60efbb2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load models\n",
    "face_cascade= cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade= cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "smile_cascade= cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "  img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "  roi_gray = gray[y:y+h, x:x+w]\n",
    "  roi_color = img[y:y+h, x:x+w]\n",
    "  eyes= eye_cascade.detectMultiScale(roi_gray)\n",
    "  for (ex,ey,ew,eh) in eyes:\n",
    "    cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "  smile=smile_cascade.detectMultiScale(roi_gray)\n",
    "  for (sx,sy,sw,sh) in smile:\n",
    "    cv2.rectangle(roi_color,(sx,sy),(sx+sw,sy+sh),(0,0,255),2)\n",
    "\n",
    "cv2.imshow(\"Image:\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f65258-3aad-4270-bf84-eb480a091e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac1d9e1-3556-46d6-b38c-545b7787cc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40819886-ffa0-440d-8bf2-91b096032f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa1a05-3622-497e-80c3-442c73fd16f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef477d9b-e9ec-472e-89b5-2d8ca179ebe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb38e48-19db-447d-829b-679a7245f792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a868cdcd-acc4-4c98-9e5c-572f1a51c108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc7e734-3339-41d7-b2d1-1ae8eb4ade50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f866716c-5c6a-4e10-a40f-758e93e90dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8273eb0-9ac1-4633-b321-2357b8fdf7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
